{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import lxml\n",
    "import re\n",
    "\n",
    "def getInjuries(team, year):\n",
    "    \"\"\"\n",
    "    Scrapes one page of injury information\n",
    "    \"\"\"\n",
    "\n",
    "    # Scrape injury information\n",
    "    content = urllib.urlopen(\"http://www.pro-football-reference.com/teams/\" + team + \"/\" + year + \"_injuries.htm\")\n",
    "    s = content.read()\n",
    "#     s = open(\"injuries.html\")\n",
    "\n",
    "    soup = BeautifulSoup(s)\n",
    "\n",
    "    table = soup.find('table')\n",
    "    # print table.prettify()\n",
    "\n",
    "    # Scrape headers into their own table\n",
    "    opponent = []\n",
    "    game = []\n",
    "    date = []\n",
    "    game_url = []\n",
    "    for num, heading in enumerate(table.findAll(\"th\")):\n",
    "    \n",
    "        this_url = heading.find_all(\"a\", href=True)\n",
    "        if (this_url) != []:\n",
    "            game_url.append(this_url[0].get('href'))\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        head = heading.get_text()\n",
    "        game.append(num)\n",
    "        date.append(head[0:5])\n",
    "        opponent.append(head[9:12])\n",
    "\n",
    "    headers = pd.DataFrame({'opponent':opponent, 'game':game, 'date':date, 'game_url':game_url})\n",
    "    \n",
    "    # Scrape body of table\n",
    "    name = []\n",
    "    player_url = []\n",
    "    status = []\n",
    "    played = []\n",
    "    injury = []\n",
    "    game = []\n",
    "\n",
    "    for row in table.findAll(\"tr\"):\n",
    "        cells = row.findAll(\"td\")\n",
    "        if (len(cells) > 0):\n",
    "            for i in range(1,len(cells)):\n",
    "                # Name\n",
    "                name.append(cells[0].get_text())\n",
    "                player_url.append(cells[0].a.get('href'))\n",
    "                \n",
    "                # Game\n",
    "                game.append(i)\n",
    "                \n",
    "                # Status\n",
    "                status.append(cells[i].get_text())\n",
    "                \n",
    "                # Played\n",
    "                if (cells[i].attrs.get('class') is not None):\n",
    "                    played.append(not('played' in cells[i].attrs.get('class')))\n",
    "                else:\n",
    "                    played.append(None)\n",
    "\n",
    "                # Injury detail\n",
    "                if cells[i].find(\"span\") != None:\n",
    "                    inj_type = str.split(cells[i].find(\"span\").attrs.get('tip').encode('utf-8'),\": \")[1]\n",
    "                    injury.append(inj_type)\n",
    "                else:\n",
    "                    injury.append(None)\n",
    "\n",
    "    body = pd.DataFrame({'name':name,'status':status,'injury':injury,'played':played,'game':game,'year':year,'team':team,\n",
    "                         'player_url':player_url})\n",
    "\n",
    "    # Merge together dataframes\n",
    "    both = pd.merge(headers, body, on = 'game')\n",
    "    cols = ['team', 'year', 'game', 'date', 'opponent', 'name', 'status', 'injury', 'played','player_url','game_url']\n",
    "    \n",
    "    both = both[cols].sort(columns=['year','team','name','game'])\n",
    "    \n",
    "    # Scrape roster information\n",
    "    content = urllib.urlopen(\"http://www.pro-football-reference.com/teams/\" + team + \"/\" + year + \"_roster.htm\")\n",
    "    s = content.read()\n",
    "    soup = BeautifulSoup(s)\n",
    "\n",
    "    table = soup.find_all('table')[1]\n",
    "    roster = pd.read_html(str(table))[0]\n",
    "    \n",
    "    new_columns = roster.columns.values\n",
    "    new_columns[1] = 'name'\n",
    "    roster.columns = new_columns\n",
    "    \n",
    "    roster['name'] = [re.sub('[*]|[+]', '', name) for name in roster['name']]\n",
    "\n",
    "    # Merge and return\n",
    "    final = pd.merge(both, roster, how = \"left\", on=\"name\")\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crd 2009\n",
      "crd 2010\n",
      "crd 2011\n",
      "crd 2012\n",
      "crd 2013\n",
      "crd 2014\n",
      "atl 2009\n",
      "atl 2010\n",
      "atl 2011\n",
      "atl 2012\n",
      "atl 2013\n",
      "atl 2014\n",
      "rav 2009\n",
      "rav 2010\n",
      "rav 2011\n",
      "rav 2012\n",
      "rav 2013\n",
      "rav 2014\n",
      "buf 2009\n",
      "buf 2010\n",
      "buf 2011\n",
      "buf 2012\n",
      "buf 2013\n",
      "buf"
     ]
    }
   ],
   "source": [
    "## Get all pages to scrape\n",
    "teams = [\"crd\", \"atl\", \"rav\", \"buf\",\"car\",\"chi\",\"cin\",\"cle\",\"dal\",\"den\",\"det\",\"gnb\",\"htx\",\"clt\",\"jax\",\"kan\",\"mia\",\"min\",\n",
    "           \"nwe\",\"nor\",\"nyg\",\"nyj\",\"rai\",\"phi\",\"pit\",\"sdg\",\"sfo\",\"sea\",\"ram\",\"tam\",\"oti\",\"was\"]\n",
    "years = ['2009','2010','2011','2012','2013','2014']\n",
    "team_years = [(x,y) for x in teams for y in years]\n",
    "\n",
    "## Scrape each of the pages\n",
    "output = pd.DataFrame()\n",
    "for a,b in team_years:\n",
    "    print a, b\n",
    "    sleep(randint(1,3))\n",
    "    sleep(randint(1,3))    \n",
    "    output = output.append(getInjuries(a,b))\n",
    "\n",
    "# Having some problems with drafted column, so I've taken that out\n",
    "output = output.drop('Drafted (tm/rnd/yr)',1)\n",
    "\n",
    "output.to_csv(\"output.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
